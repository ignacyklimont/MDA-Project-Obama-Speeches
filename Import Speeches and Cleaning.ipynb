{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fe9b50ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Tom\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words=stopwords.words('english')\n",
    "stop_words.extend([\"ad\",\"quot\",\"ca\"])\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('words')\n",
    "words = set(nltk.corpus.words.words())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6336f6",
   "metadata": {},
   "source": [
    "Get speeches from website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d426792f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To open the csv file with the cleaned speeches use \n",
    "# with open('speeches_clean.csv', newline = '') as file:\n",
    "#     reader = csv.reader(file)\n",
    "#     \"name\" = list(reader)\n",
    "\n",
    "\n",
    "with open('Speeches.csv', newline='') as file:\n",
    "    reader = csv.reader(file)\n",
    "    data = list(reader)\n",
    "data = data[28:len(data)-1] # Start with first victory speech, last entry is not a speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "44b9e9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary items from the list, result = ['title', 'url', 'date'] for each speech\n",
    "for i in reversed(range(len(data))):\n",
    "    data[i] = [x for x in data[i] if not x == '' if not 'mp3' in x if not 'pdf' in x if not 'PDF' in x]\n",
    "    if len(data[i]) != 3:\n",
    "        data.remove(data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b33b1fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the speeches from the website (this step takes 3-5 min)\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:25.0) Gecko/20100101 Firefox/25.0'}\n",
    "\n",
    "speeches_raw = list()\n",
    "for i in range(len(data)):\n",
    "    r = requests.get(data[i][1], headers = headers)\n",
    "    speeches_raw.append((data[i][0],data[i][2],r.text))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a8be53",
   "metadata": {},
   "source": [
    "Function for cleaning the speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d90cbdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_speeches(speeches):\n",
    "    # Remove html code and white spaces\n",
    "    speeches = speeches.lower()\n",
    "    speeches = re.sub('<.*>', '', speeches)\n",
    "    speeches = re.sub('\\((.*?\\))', '', speeches)\n",
    "    speeches = re.sub('\\[.*?\\]', '', speeches)\n",
    "    speeches = re.sub('[%s]' % re.escape(string.punctuation), ' ', speeches)\n",
    "    speeches = re.sub('\\w*\\d\\w*', '', speeches)\n",
    "    speeches = re.sub('\\n*\\r*\\t*', '', speeches)\n",
    "    # Remove stop words\n",
    "    tokenized_speeches=word_tokenize(speeches)\n",
    "    speeches_wo_stopwords= [w for w in tokenized_speeches if not w in stop_words] \n",
    "    speeches_wo_stopwords=' '.join(speeches_wo_stopwords) \n",
    "    # Remove non-English words\n",
    "    speeches_wo_nonwords = [w for w in nltk.wordpunct_tokenize(speeches_wo_stopwords) if w.lower() in words or not w.isalpha()]\n",
    "    speeches_wo_nonwords = ' '.join(speeches_wo_nonwords)\n",
    "    return speeches_wo_nonwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de03ff13",
   "metadata": {},
   "source": [
    "Cleaning the speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0a22ed04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "speeches_clean = list()\n",
    "for i in range(0,len(speeches_raw)):\n",
    "    clean_txt = cleaning_speeches(speeches_raw[i][2])\n",
    "    speeches_clean.append((speeches_raw[i][0],speeches_raw[i][1],clean_txt[180:-180])) #remove the first and last few words, since they are not part of the speeches (unfortunately, not the same amount for each speech though)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "eb3110f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ll dream alive time still power democracy tonight answer answer told around nation never seen people three four many first time time must different could difference answer spoken young old rich poor democrat republican black white native gay straight disabled disabled sent message world never collection collection red blue always united answer led told long many cynical fearful doubtful achieve put arc history bend toward hope better day long time coming tonight day election moment change come little bit evening received extraordinarily gracious call senator senator fought long hard campaign fought even longer harder country us begin imagine better service brave selfless leader congratulate congratulate governor look forward working renew nation promise ahead want thank partner journey man heart spoke men grew streets rode train home vice president elect united joe would standing tonight without unyielding support best friend last rock family love life nation next first lady love imagine new puppy coming us white house longer us know grandmother watching along family made miss tonight know debt beyond measure sister maya sister alma thank much support given grateful campaign manager unsung hero campaign built best best political campaign think history united chief strategist partner every step way best campaign team ever history politics made happen forever grateful get done never forget victory truly never candidate office start much money many campaign living concord front built working men dug little give cause grew strength young people myth generation apathy left little pay less sleep drew strength young people bitter cold scorching heat knock perfect millions organized proved two later government people people people perished earth victory know win election know understand enormity task ahead even celebrate tonight know tomorrow bring lifetime two planet peril worst financial crisis century even stand tonight know brave waking risk us lie awake fall asleep wonder make mortgage pay save enough child college education new energy harness new new build meet repair road ahead long climb steep may get one year even one term never hopeful tonight get promise people get false many agree every decision policy make president know government solve every problem always honest face listen especially disagree ask join work nation way done block block brick brick hand hand ago winter end autumn night victory alone change seek chance us make change happen go back way happen without without new spirit service new spirit sacrifice let us summon new spirit patriotism responsibility us pitch work harder look let us remember financial crisis taught us anything thriving wall street main street country rise fall one nation one people let resist temptation fall back partisanship pettiness immaturity politics long let remember man state first carried banner republican party white house party self reliance individual liberty national unity share democratic party great victory tonight measure humility determination heal back progress said nation far divided though passion may strained must break affection whose support yet earn may vote tonight hear need help president watching tonight beyond around forgotten world singular destiny new dawn leadership hand would tear world defeat seek peace security support beacon still bright tonight proved true strength nation comes might arms scale wealth enduring power democracy liberty opportunity unyielding hope true genius change union perfected already us hope must achieve tomorrow election many many told one mind tonight woman cast ballot lot like millions stood line make voice election except one thing ann born generation past slavery time road sky someone like vote two woman color skin tonight think seen throughout century heartache hope struggle progress times told people creed yes time silenced lived see stand speak reach ballot yes despair dust bowl depression across land saw nation conquer fear new new sense common purpose yes fell harbor witness generation rise greatness democracy saved yes preacher told people shall overcome yes man touched moon world connected science imagination year election touched finger screen cast vote best times change yes come far seen much much tonight let us ask live see next century lucky live long ann cooper change see progress made chance answer call moment time put people back work open opportunity restore prosperity promote cause peace reclaim dream reaffirm fundamental truth many one breathe hope met cynicism doubt tell us respond timeless creed spirit people yes book e hill second inaugural democratic national convention keynote address archive class style display block width height data client pub d'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches_clean[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c3234314",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(speeches_clean)\n",
    "df.columns = ['Title', 'Date', 'Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ad3721df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('speeches_clean.csv', index=False, header='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a310eec1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}